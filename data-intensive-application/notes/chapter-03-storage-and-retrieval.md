# Chapter 3: Storage and Retrieval

## Core Concept

> "A database needs to do two things: store data when given, and return it when asked."

**What it is:** This chapter covers how databases physically store data on disk and how they retrieve it efficiently.

**Why it matters for interviews:** Understanding storage engines helps you:
- Explain why you'd pick Cassandra vs PostgreSQL for a specific workload
- Debug performance issues (why are writes slow? why are reads slow?)
- Design systems that scale appropriately

> ğŸ’¡ **Interview Tip:** When asked "what database would you use?", never just name a database. Explain the access patterns first, then match to a storage engine type.

---

## Two Families of Storage Engines

**What they are:** All databases fall into two camps based on how they organize data on disk.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Storage Engines                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚     Log-Structured     â”‚         Page-Oriented              â”‚
â”‚     (LSM-Trees)        â”‚         (B-Trees)                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â€¢ Append-only writes   â”‚ â€¢ In-place updates                 â”‚
â”‚ â€¢ Compaction needed    â”‚ â€¢ Fixed-size pages                 â”‚
â”‚ â€¢ Better write perf    â”‚ â€¢ Better read perf                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ RocksDB, LevelDB,      â”‚ PostgreSQL, MySQL,                 â”‚
â”‚ Cassandra, HBase       â”‚ Oracle, SQL Server                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Why two families?** It's fundamentally about sequential vs random I/O. SSDs are fast, but sequential writes are still 10-100x faster than random writes. LSM-trees exploit this.

---

## Log-Structured Storage (LSM-Trees)

### The Simplest Database

**What it is:** A log is just an append-only file. The simplest database is literally two bash functions:

```bash
#!/bin/bash
# World's simplest key-value store
db_set() { echo "$1,$2" >> database; }
db_get() { grep "^$1," database | sed "s/^$1,//" | tail -n 1; }

# Usage:
db_set user123 '{"name":"Alice"}'
db_get user123  # Returns: {"name":"Alice"}
```

**Why this matters:** This is the foundation of ALL log-structured storage. Every LSM-tree database is a sophisticated version of this.

**The trade-off:**
- Writes: O(1) âœ“ (just append to end of file - sequential I/O)
- Reads: O(n) âœ— (scan entire file to find key!)

**Solution:** Add an index to speed up reads without sacrificing write speed!

### Hash Index (In-Memory)

**What it is:** Keep a hashmap in memory that maps each key to its byte offset in the log file.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Hash Index                                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚
â”‚   In-Memory HashMap          Log File on Disk              â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚
â”‚   â”‚ key â†’ offset  â”‚          â”‚ 0: user1,{...}  â”‚           â”‚
â”‚   â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤   â”€â”€â”€â–º   â”‚ 42: user2,{...} â”‚           â”‚
â”‚   â”‚ user1 â†’ 0     â”‚          â”‚ 87: user1,{...} â”‚           â”‚
â”‚   â”‚ user2 â†’ 42    â”‚          â”‚ 120: user3,{...}â”‚           â”‚
â”‚   â”‚ user3 â†’ 120   â”‚          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                        â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Why this works:** Writes are still O(1) (append + update hashmap), but reads are now O(1) (lookup offset, seek to position).

**Used by:** Bitcask (Riak's default engine)

**When to use hash indexes:**
- âœ… High write throughput with frequent updates to same keys (like URL shorteners, video view counts)
- âœ… Workloads where all keys fit in RAM

**Limitations:**
- âŒ All keys must fit in memory (can't handle billions of small keys)
- âŒ Range queries inefficient (can't ask "all users from A-M")

> ğŸ’¡ **Interview Tip:** When someone asks about key-value stores, mention that the choice of index structure determines the trade-offs. Hash = fast point lookups but no range queries.

### SSTables and LSM-Trees

**What it is:** SSTable (Sorted String Table) = log segments where keys are sorted. LSM-Tree = a tree of SSTables at different levels.

**Why sorted?** Sorting enables:
1. Efficient merging (like merge-sort)
2. Sparse indexes (don't need every key in memory)
3. Range queries

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  LSM-Tree Write Path                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚
â”‚   1. Write to memtable (in-memory sorted tree)             â”‚
â”‚                                                             â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                         â”‚
â”‚   â”‚   Memtable   â”‚  â† All writes go here first             â”‚
â”‚   â”‚ (Red-Black)  â”‚    (kept sorted in memory)              â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜                                         â”‚
â”‚          â”‚ Flush when full (~few MB)                       â”‚
â”‚          â–¼                                                  â”‚
â”‚   2. Flush to SSTable on disk                              â”‚
â”‚                                                             â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                         â”‚
â”‚   â”‚  SSTable-1   â”‚  â† Immutable, sorted, compressed        â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                         â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                         â”‚
â”‚   â”‚  SSTable-2   â”‚  â† Older data                           â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                         â”‚
â”‚          â”‚                                                  â”‚
â”‚          â–¼                                                  â”‚
â”‚   3. Background compaction merges SSTables                 â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Why a memtable?** You can't append to a sorted file (you'd have to rewrite it). Instead, buffer writes in a sorted in-memory structure, then flush as a sorted segment.

**Compaction Strategies:**

```
Size-Tiered (Cassandra default, HBase):
â”Œâ”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”
â”‚ S1 â”‚ â”‚ S2 â”‚ â”‚ S3 â”‚  â†’ When similar-sized, merge them
â””â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”˜
- Good for write-heavy workloads
- Can use lots of disk space temporarily

Leveled (LevelDB, RocksDB):
Level 0: â”Œâ”€â”€â” â”Œâ”€â”€â” â”Œâ”€â”€â”     (overlapping keys allowed)
Level 1: â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  (non-overlapping, 10x bigger)
Level 2: â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
- Better read performance (fewer files to check)
- More consistent space usage
- Higher write amplification
```

**What is write amplification?** Data gets written multiple times (memtable â†’ SSTable â†’ compacted SSTable). A single 1KB write might result in 10-30KB of actual disk writes.

### LSM-Tree Read Path

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  LSM-Tree Read Path                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚
â”‚   Read key "user123":                                       â”‚
â”‚                                                             â”‚
â”‚   1. Check memtable          â”€â”€â–º Found? Return             â”‚
â”‚          â”‚                                                  â”‚
â”‚          â–¼ Not found                                        â”‚
â”‚   2. Check SSTable-1 (newest) â”€â”€â–º Found? Return            â”‚
â”‚          â”‚                                                  â”‚
â”‚          â–¼ Not found                                        â”‚
â”‚   3. Check SSTable-2          â”€â”€â–º Found? Return            â”‚
â”‚          â”‚                                                  â”‚
â”‚          â–¼ Not found                                        â”‚
â”‚   4. ... older SSTables ...                                â”‚
â”‚          â”‚                                                  â”‚
â”‚          â–¼                                                  â”‚
â”‚   5. Not found anywhere â†’ Return null                      â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Why LSM reads can be slow:** For a missing key, you check EVERY level. This is the read amplification problem.

**Bloom Filter: The Solution**

**What it is:** A probabilistic data structure that answers "is this key present?" 
- "Definitely NOT present" â†’ Skip this SSTable (saves a disk read!)
- "Maybe present" â†’ Check the SSTable

**Why it works:** A bloom filter is a bit array with multiple hash functions. False positives possible (says "maybe" when key isn't there), but false negatives impossible (never says "no" when key IS there).

> ğŸ’¡ **Interview Tip:** Always mention bloom filters when discussing LSM-trees. They're crucial for read performance and show you understand the read amplification problem.

---

## B-Trees (Page-Oriented Storage)

### What it is

B-Trees break the database into fixed-size pages (typically 4KB) and organize them as a balanced tree. Unlike LSM-trees, B-trees update data IN-PLACE.

**Why B-Trees are everywhere:** They've been the standard for 40+ years. Every traditional RDBMS uses them because they provide consistent, predictable performance.

### Structure

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      B-Tree Structure                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚
â”‚                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                          â”‚
â”‚                    â”‚  [100|200]  â”‚  â† Root page             â”‚
â”‚                    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜                          â”‚
â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                    â”‚
â”‚              â–¼            â–¼            â–¼                    â”‚
â”‚        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”               â”‚
â”‚        â”‚ [30|70] â”‚  â”‚[130|170]â”‚  â”‚[250|300]â”‚  â† Internal   â”‚
â”‚        â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜               â”‚
â”‚        â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”       â”‚       â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”               â”‚
â”‚        â–¼         â–¼       â–¼       â–¼         â–¼               â”‚
â”‚    â”Œâ”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”           â”‚
â”‚    â”‚leaf  â”‚ â”‚leaf  â”‚ â”‚leaf  â”‚ â”‚leaf  â”‚ â”‚leaf  â”‚  â† Leaves â”‚
â”‚    â”‚data  â”‚ â”‚data  â”‚ â”‚data  â”‚ â”‚data  â”‚ â”‚data  â”‚   (pages) â”‚
â”‚    â””â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”˜           â”‚
â”‚                                                             â”‚
â”‚   Page size: typically 4KB (matches OS page size)          â”‚
â”‚   Branching factor: ~500 (keys per page)                   â”‚
â”‚   Depth: 3-4 levels handles BILLIONS of keys               â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Why so shallow?** With branching factor of 500: 500^4 = 62.5 billion keys in just 4 levels. Most reads need only 3-4 disk seeks.

### Write-Ahead Log (WAL)

**What it is:** Before modifying any B-tree page, write the intended change to a sequential log file first.

**Why it's necessary:** B-tree writes are in-place. If you crash mid-write, the page is corrupted. WAL ensures you can recover.

```
Write "user123" â†’ {"name": "Alice"}

1. Append to WAL (fast sequential write)
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ WAL: [SET user123 {"name":"Alice"}] â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

2. Update B-tree page (slower random I/O)
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ Page 42: [user123|Alice|...]        â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

If crash after step 1 but before step 2:
â†’ On restart, replay WAL to recover the write
```

> ğŸ’¡ **Interview Tip:** WAL is used for crash recovery AND replication. PostgreSQL streams WAL to replicas. This is "physical replication" vs "logical replication" (streaming SQL statements).

---

## LSM-Trees vs B-Trees: The Key Decision

**When someone asks "which database should I use?", this is the fundamental trade-off:**

| Aspect | LSM-Trees | B-Trees |
|--------|-----------|---------|
| **Write throughput** | Higher (sequential I/O) | Lower (random I/O) |
| **Read latency** | Variable (check multiple levels) | Predictable (single location) |
| **Space efficiency** | Better (compression, no fragmentation) | Some fragmentation |
| **Write amplification** | Higher (compaction rewrites data) | Lower |
| **Read amplification** | Higher (multiple SSTables) | Lower (single tree) |
| **Latency spikes** | Yes (compaction) | No |

### Real-World Decision Guide

**Choose LSM-Tree (Cassandra, RocksDB, HBase) when:**
- Write-heavy workload (logging, IoT, time-series)
- High throughput matters more than latency consistency
- Storage cost matters (better compression)
- Example: "We need to ingest 1 million events/second"

**Choose B-Tree (PostgreSQL, MySQL) when:**
- Read-heavy or mixed workload
- Need consistent, predictable latency (SLAs)
- Transactions are important (easier to implement ACID)
- Example: "Users expect sub-100ms response times"

> ğŸ’¡ **Interview Tip:** Don't just say "Cassandra is faster for writes." Explain WHY: sequential I/O, no random seeks, no page splits. Show you understand the mechanics.

---

## OLTP vs OLAP: Two Different Worlds

**What's the difference?** OLTP and OLAP aren't just workload typesâ€”they need fundamentally different storage designs.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              OLTP vs OLAP Workloads                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚        OLTP            â”‚           OLAP                     â”‚
â”‚  (Online Transaction)  â”‚  (Online Analytical)               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Many small txns        â”‚ Few large scans                    â”‚
â”‚ Read/write single rows â”‚ Read millions of rows              â”‚
â”‚ Latest state           â”‚ Historical analysis                â”‚
â”‚ User-facing apps       â”‚ Business intelligence              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ MySQL, PostgreSQL      â”‚ Snowflake, Redshift, BigQuery     â”‚
â”‚ MongoDB                â”‚ ClickHouse, DuckDB                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Real examples:**
- **OLTP:** "Show me order #12345" (point lookup, low latency)
- **OLAP:** "What were total sales by region last quarter?" (scan millions of rows)

**Why separate systems?** 
- OLTP optimized for random access to individual rows
- OLAP optimized for scanning huge amounts of data
- Running analytics on your production DB can kill it!

### Data Warehouse Architecture

**What it is:** A separate database optimized for analytics, fed by ETL from production systems.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                             â”‚
â”‚   OLTP DBs          ETL              Data Warehouse         â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”                           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚   â”‚Ordersâ”‚ â”€â”€â”                       â”‚                â”‚     â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”˜   â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚   Fact Tables  â”‚     â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”   â”œâ”€â”€â”€â–ºâ”‚ Extract  â”‚       â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚     â”‚
â”‚   â”‚Users â”‚ â”€â”€â”¤    â”‚Transform â”‚â”€â”€â”€â”€â”€â”€â–ºâ”‚  â”‚  Sales   â”‚  â”‚     â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”˜   â”‚    â”‚  Load    â”‚       â”‚  â”‚  Facts   â”‚  â”‚     â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”   â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚     â”‚
â”‚   â”‚Prods â”‚ â”€â”€â”˜                       â”‚                â”‚     â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”˜                           â”‚ Dimension Tbls â”‚     â”‚
â”‚                                      â”‚  â”Œâ”€â”€â”€â”€â”€â”â”Œâ”€â”€â”€â”€â”€â”â”‚     â”‚
â”‚                                      â”‚  â”‚Date â”‚â”‚Prod â”‚â”‚     â”‚
â”‚                                      â”‚  â””â”€â”€â”€â”€â”€â”˜â””â”€â”€â”€â”€â”€â”˜â”‚     â”‚
â”‚                                      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Star Schema:** Fact tables (events/transactions) reference dimension tables (who, what, when, where). Called "star" because diagram looks like a star.

> ğŸ’¡ **Interview Tip:** When designing analytics systems, mention star schema and explain why denormalization is OK here (read-heavy, no updates to historical data).

---

## Column-Oriented Storage

### Row vs Column Storage: Why It Matters

**What it is:** Instead of storing all columns of a row together, store all values of each column together.

```
Row-oriented (OLTP - PostgreSQL, MySQL):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Row 1: date|product|price|quantity  â”‚  â† Entire row stored together
â”‚ Row 2: date|product|price|quantity  â”‚
â”‚ Row 3: date|product|price|quantity  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Column-oriented (OLAP - ClickHouse, Redshift):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ date column:   â”‚ 2024-01-01, 2024-01-01, 2024-01-02...
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ product column:â”‚ Widget, Gadget, Widget...
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ price column:  â”‚ 29.99, 49.99, 29.99...
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ quantity col:  â”‚ 100, 50, 200...
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Why Column Storage Wins for Analytics

```sql
-- Typical analytics query
SELECT product, SUM(quantity * price) as revenue
FROM sales
WHERE date BETWEEN '2024-01-01' AND '2024-12-31'
GROUP BY product;
```

**Row storage:** Must read ALL columns of every row, even though we only need 4 columns. For a 100-column table, we read 25x more data than needed!

**Column storage:** Read ONLY the 4 columns needed. Plus columns compress much better (similar values grouped together).

**The numbers:** Column stores routinely achieve 10x compression ratios and 10-100x faster analytics queries.

### Column Compression Techniques

**Why columns compress well:** Similar values are adjacent. A "country" column might have "USA" repeated millions of times.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚               Bitmap Encoding Example                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚
â”‚   product_id values: [A, B, A, A, C, B, A, C, C, A]        â”‚
â”‚                                                             â”‚
â”‚   Bitmap for A: [1,0,1,1,0,0,1,0,0,1]                      â”‚
â”‚   Bitmap for B: [0,1,0,0,0,1,0,0,0,0]                      â”‚
â”‚   Bitmap for C: [0,0,0,0,1,0,0,1,1,0]                      â”‚
â”‚                                                             â”‚
â”‚   WHERE product = 'A' â†’ just scan bitmap A (super fast!)   â”‚
â”‚   WHERE product IN ('A','B') â†’ bitmap A OR bitmap B        â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**When to use bitmaps:** Low-cardinality columns (country, status, category). Not for high-cardinality (user_id, email).

### Run-Length Encoding

```
Original:   [A,A,A,A,A,B,B,C,C,C,C,C,C,C,C]
Encoded:    [(A,5), (B,2), (C,8)]

15 values â†’ 6 values (60% compression!)
```

**When this shines:** Sorted columns. If you sort by date, then by product, the product column will have long runs of the same value.

> ğŸ’¡ **Interview Tip:** When discussing analytics databases, explain that column storage isn't just about reading fewer columnsâ€”it's about enabling compression techniques that are impossible with row storage.

---

## Practical Index Types

### Secondary Indexes

**What's the difference?**

```sql
-- Primary key / clustered index: rows physically stored in this order
CREATE INDEX ON users(id);  

-- Secondary index: separate structure pointing to row locations
CREATE INDEX ON users(email);  
```

**Why it matters:** Clustered index lookups are faster (data is right there). Secondary indexes require an extra hop to fetch the actual row.

### Multi-Column (Composite) Indexes

**The leftmost prefix rule:** A composite index on (a, b, c) can be used for queries on (a), (a, b), or (a, b, c), but NOT (b) or (c) alone.

```sql
-- Concatenated index
CREATE INDEX ON events(year, month, day);

-- Query optimization:
WHERE year = 2024                    -- Uses index âœ“
WHERE year = 2024 AND month = 1      -- Uses index âœ“
WHERE year = 2024 AND month = 1 AND day = 15  -- Uses index âœ“
WHERE month = 1                       -- Cannot use index âœ—
WHERE month = 1 AND day = 15          -- Cannot use index âœ—
```

> ğŸ’¡ **Interview Tip:** When asked about slow queries, always check if the WHERE clause matches the index's leftmost columns. This is a common gotcha.

### Full-Text Search Index (Inverted Index)

**What it is:** Maps words â†’ documents that contain them (the reverse of a normal index).

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   Inverted Index                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚
â”‚   Documents:                                                â”‚
â”‚   Doc1: "The quick brown fox"                              â”‚
â”‚   Doc2: "The lazy dog"                                     â”‚
â”‚   Doc3: "Quick brown dog"                                  â”‚
â”‚                                                             â”‚
â”‚   Inverted Index:                                          â”‚
â”‚   "brown" â†’ [Doc1, Doc3]                                   â”‚
â”‚   "dog"   â†’ [Doc2, Doc3]                                   â”‚
â”‚   "fox"   â†’ [Doc1]                                         â”‚
â”‚   "lazy"  â†’ [Doc2]                                         â”‚
â”‚   "quick" â†’ [Doc1, Doc3]                                   â”‚
â”‚   "the"   â†’ [Doc1, Doc2]                                   â”‚
â”‚                                                             â”‚
â”‚   Search "brown dog" â†’ intersect([Doc1,Doc3], [Doc2,Doc3]) â”‚
â”‚                      â†’ Doc3                                 â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Used by:** Elasticsearch, Solr, PostgreSQL full-text search

**When to use:** Search engines, log analysis, any "find documents containing..." query

---

## Key Takeaways

1. **Two engine families:** LSM-Trees (write-optimized, sequential I/O) vs B-Trees (read-optimized, in-place updates)
2. **OLTP vs OLAP:** Different workloads need fundamentally different storage designs
3. **Column storage:** Essential for analyticsâ€”read less data, compress better
4. **Index trade-off:** Every index speeds up reads but slows down writes
5. **Know your access patterns:** The "best" database depends entirely on how you'll use it

---

## Quick Reference

| Workload | Storage Engine | Database Examples |
|----------|----------------|-------------------|
| Write-heavy OLTP | LSM-Tree | Cassandra, RocksDB, ScyllaDB |
| Read-heavy OLTP | B-Tree | PostgreSQL, MySQL |
| Analytics (OLAP) | Column-oriented | ClickHouse, Redshift, Snowflake |
| Full-text search | Inverted index | Elasticsearch, Solr |
| Time series | LSM + Time partitions | InfluxDB, TimescaleDB |

---

## System Design Interview Tips

1. **Start with access patterns:** "Before choosing a database, let me understand the read/write ratio and query patterns."

2. **Explain the WHY:** Don't just say "I'd use Cassandra." Say "Cassandra uses LSM-trees which are optimized for high write throughput because writes are sequential."

3. **Mention trade-offs:** "LSM-trees give us great write throughput, but we might see latency spikes during compaction. For user-facing reads, we might add a caching layer."

4. **Know real numbers:** 
   - B-tree lookup: 3-4 disk seeks for billions of keys
   - SSD random read: ~100Î¼s
   - SSD sequential read: ~10Î¼s per KB

5. **Connect to real systems:**
   - "Uber uses Cassandra for high-write workloads like trip events"
   - "Facebook uses RocksDB as an embedded storage engine"
   - "Most traditional web apps use PostgreSQL because the B-tree's predictable latency matters"

---

## Common Interview Questions

**Q: "Why would you choose Cassandra over PostgreSQL?"**
A: Cassandra uses LSM-trees optimized for write-heavy workloads. It handles high write throughput well because it turns random writes into sequential writes. Use it when you need to ingest massive amounts of data (logging, IoT, events). PostgreSQL's B-tree is better when you need consistent read latency and complex queries.

**Q: "Why do analytics databases use column storage?"**
A: Analytics queries typically read few columns but many rows. Column storage lets you read only the columns you need and enables much better compression (similar values grouped together). A query scanning 1 billion rows but only 3 columns reads 97% less data in a column store vs row store.

**Q: "What's write amplification and why does it matter?"**
A: Write amplification means one logical write causes multiple physical writes. In LSM-trees, data is written to memtable, then flushed to SSTable, then rewritten during compactionâ€”possibly 10-30x amplification. This affects SSD lifespan and throughput. It's the price you pay for fast sequential writes.

**Q: "How would you handle a slow query in PostgreSQL?"**
A: First, check EXPLAIN ANALYZE to see if indexes are being used. Common issues: missing index, index not matching query's leftmost columns, or too many rows being scanned. Consider if the query pattern matches the storage engineâ€”if it's analytics-heavy, maybe it belongs in a column store.
